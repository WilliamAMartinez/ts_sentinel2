---
title: "Analysis of outliers in the training data COS by using NDVI over the time"
author: "William Martinez"
date: "30 de octubre de 2018"
output: html_document
---

##Introduction

The purpose of this vignette is to document the process of removing outliers in the data set COS in the environment of R with the aim at exploring different accuraccies that we can achieve in the classification for the year 2017. As part of the supervised clasification, besides the imagery for 2017, we account with a training dataset COS (Carta de uso e Ocupacao do solo) composed by 15000 samples categorized by different LCLU types (1000 samples each type). Since our training dataset differs in date and source of adquisition respect the imagery (aerial imagery), we need to trace the differences between what the labels explain and what actually happens in the ground. 


##Methodology 

Therefore, as first attempt to explore those differences, we recreated the NDVI for 29 images available for the year 2017 an extract the NDVI values to the 15000 points (see vignette python "NDVI compositions"). Since We expect certain homogeinity in the NDVI values per class and per time, we think that the set of those values that do not follow this trend are probably points that may change for natural or anthropogenic reasons; or simply the label is not enough representation of the area covered by the pixel.  

Therefore, to measure the statistical dispersion of NDVI per class and per time we are going to use two methods, interquantile ranges and standart deviations. 


```{r}
library(sf)
library(ggplot2)
folder_path = "D:\\TESISMASTER\\VECTOR\\Analysis_outliers\\training_samples.shp"
#Days of the images
day_shoot = c("2017/01/15", "2017/04/05", "2017/05/25", "2017/06/04", "2017/06/14",
              "2017/07/04", "2017/07/09", "2017/07/14", "2017/07/24", "2017/07/29",
              "2017/08/03", "2017/08/08", "2017/08/13", "2017/08/18", "2017/09/02" ,
              "2017/09/07", "2017/09/12", "2017/09/22", "2017/09/27", "2017/10/02",
              "2017/10/12", "2017/10/22", "2017/10/27", "2017/11/11", "2017/11/16",
              "2017/11/21", "2017/12/01","2017/12/16", "2017/12/21")
#Name of the classes
clases =    c("Sealed", "Non_vegetated","Herbaceous_periodic","Herbaceous_permanet",
            "Natural_Herbaceous","Bushes_and_shrubs","Vineyard","Olive_trees",
            "Holm_and_Cork_Trees", "Eucalyptus_trees", "Coniferous_trees","Rice_fields",
            "Orchards")
#converting days characters to time format in R 
day_shoot= strptime(as.character(day_shoot), "%Y/%m/%d")
#reading shapefile
dataset = sf::read_sf(folder_path)
#creating a copy to save later the files
dataset_c = dataset
#Removing geometry of the dataset
st_geometry(dataset) = NULL
```


###Method 1: interquantile range analysis

IQR method makes detection of ouliers by looking at values more than one and half times the IQR distance below the first quartil and above the third quartil. IQR analysis is attractive because it considers the median as the measurement of centrality and thus is considered resistant to outliers. The following equations shows how to calculate this range per time for especific land cover type.

$$
IQR^{t} = Q_{3}^{t} - Q_{1}^{t} 
$$
$$
Limits^{t} = Q_{1}^{t} \pm  1.5*IQR^{t} 
$$

```{r}

model1 =  function(x){
  ind_list = list()
  qua = quantile(x,na.rm=TRUE)
  q25 =qua[2]
  q75 =qua[4]
  IQR = q75 - q25
  limit_left = q25 - 1.5*IQR
  limit_rigth = q75 + 1.5*IQR
  ind = which(x<= limit_left | x >= limit_rigth)
  return(ind)
}
```


###Method 2: Standard deviation analysis

And alternative to interquantile range analysis is to explore the values that are at different standard deviations from the mean of the data (here two standard deviations). Standard deviation analysis is also a measurement of dispersion, however, it is problematic for not being resistant to the presence of outliers and, furthermore, it works under the assumption that data must follow certain normality.  

$$
Limits^{t} = \bar{x}^{t} \pm  n \cdot \sigma ^{t}
$$


```{r}

model2 =  function(x){
  sd_x = sd(x,na.rm = TRUE)
  mean_x = mean(x,na.rm = TRUE)
  limit_left = mean_x - 2*sd_x
  limit_rigth = mean_x + 2*sd_x
  ind = which(x<= limit_left | x >= limit_rigth)
  return(ind)
}

```


###Implementation

Well, basically the next function apply the previous methods and return a suitable dataframe for the use of ggplot2 library.

```{r}

df_without_outliers = function(query_dataset,
                               methodo = c("None","model_1", "model_2"),
                               day_shoot){
  #selecting model
  list_out = vector("list",2)
  func_choice <- switch(methodo,
                       'None'='None',
                       'model_1'=model1,
                       'model_2'=model2
                       )
  w = NULL
  if(is.function(func_choice)){
    outlier_indices = apply(query_dataset,2,func_choice)
    for(j in outlier_indices)
    {
      if(length(j)!= 0){
        w = c(w,j)
        }
    }
    #removing repeated values and quering only valid values
    query_dataset_vv = query_dataset[-unique(w),]
    list_out[[1]] = length(unique(w))
    list_out[[2]] = unique(w)
  }else{
    query_dataset_vv = query_dataset
    list_out[[1]] = 0
    list_out[[2]] = 0
  }

  output_all = NULL
  for(i in 1:dim(query_dataset_vv)[2])
  {
    trajectory = as.factor(c(1:dim(query_dataset_vv)[1]))
    ndvi_day_output = data.frame(day_shoot[i],trajectory,query_dataset_vv[,i])
    colnames(ndvi_day_output) = c('Days','Trajectory','NDVI')
    output_all = rbind(output_all, ndvi_day_output)
  }
  #Converting day in time format 
  output_all$Days = as.Date(output_all$Days)
  list_out[[3]] = output_all
  return(list_out)
  #done
}
```

##Results

The following graphic does not apply any cleanning method, therefore, this simply represents the NDVI values for rice LCLU type over the year 2017. 

```{r}
query_dataset = dataset[dataset$CLASS_NAME == "Rice_fields",c(-1,-2)]
df = df_without_outliers(query_dataset,methodo = "None", day_shoot)

#graphic
ggplot(df[[3]], aes(x=Days)) +
  geom_line(aes(y=NDVI, group=Trajectory, color='blue'),show.legend = FALSE) +
  theme(axis.text=element_text(size=13)) +
  labs(title="Time Series Rice Fields", 
       subtitle=paste0("Row data"," 1000 samples, ", df[[1]], " out, ", (df[[1]]/1000)*100,"%" ), 
       y="NDVI", 
       color=NULL) 

```

With a set of trajectories in a plot that does not show any visual tendency we set out the implementation of the proposed methods to remove those outliers that can hinder the performance of the classification. 

###Interquantile range analysis

with 25% of the information out, we can appreaciate a global tendency of the trajectories of NDVI for rice fields. The highest values are between june and october compared to the rest of the year. 

```{r}
df = df_without_outliers(query_dataset,methodo = 'model_1', day_shoot)

#graphic
ggplot(df[[3]], aes(x=Days)) +
  geom_line(aes(y=NDVI, group=Trajectory, color='red'),show.legend = FALSE) +
  labs(title="Time Series Rice fields", 
       subtitle=paste0("Method: IQR ± 1.5Q, from 1000 samples ", df[[1]], " are out: ", (df[[1]]/1000)*100,"%" ), 
       y="NDVI", 
       color=NULL)
```


```{r, echo=FALSE}
#l = 1
#for( i in unique(dataset$CLASS_NAME)){
#  file_shape = paste0("D:\\TESISMASTER\\VECTOR\\Analysis_outliers\\Model_IQR\\",l,".shp")
#  query_dataset_f = dataset[dataset$CLASS_NAME == i,c(-1,-2)]
#  query_dataset_c = dataset_c[dataset_c$CLASS_NAME == i,c(2)]
#  df = df_without_outliers(query_dataset_f,methodo = "model_1", day_shoot)
#  sf::write_sf(query_dataset_c[-df[[2]],],dsn = file_shape)
#  l = l + 1
#}
```

###Mean and standart deviation analysis

With 34% of the information out of the sampling rice fields, the tendency of the trajectories looks the same to the interquartile range graphic. However, the implementation of this method impacted highly the amount of the data available for this category, leaving almost 10% more of the original data than the previous technique.

```{r}
df = df_without_outliers(query_dataset,methodo = 'model_2', day_shoot)

#graphic
ggplot(df[[3]], aes(x=Days)) +
  geom_line(aes(y=NDVI, group=Trajectory, color='red'),show.legend = FALSE) +
  labs(title="Time Series Rice fields", 
       subtitle=paste0("Method: Mean ± sd, from 1000 samples ", df[[1]], " are out: ", (df[[1]]/1000)*100,"%" ), 
       y="NDVI", 
       color=NULL) 

```

##Conclusions

I think the better way to show which works better than other is by implementing the classification using both hypothesis. 

##Before passing to the classification

Assuming that we apply the interquantile range analysis for all the LCLU types, let's see how much differs one trajectory of NDVI respect another for certain levels of classification.

```{r, echo=FALSE}
dataset2 = dataset_c[1,]
for( i in unique(dataset$CLASS_NAME)){
  index = which(dataset_c$CLASS_NAME == i)
  query_dataset_f = dataset[index,c(-1,-2)]
  df = df_without_outliers(query_dataset_f,methodo = "model_1", day_shoot)
  index2 = index[-df[[2]]]
  dataset2 = rbind(dataset2, dataset_c[index2,])
}
#removing firs column
dataset2 = dataset2[-1,]
st_geometry(dataset2) = NULL
```

let's see first now how many samples we have per class
```{r, echo=FALSE}
output_df =  NULL
for(w in unique(dataset2$CLASS_NAME)){
  len_d1 = length(which(dataset$CLASS_NAME == w))
  len_d2 = length(which(dataset2$CLASS_NAME == w))
  ln_data = c(len_d1-len_d2,len_d2)
  name_data = c("Data1","Data2")
  ldf = data.frame(w,name_data,ln_data)
  output_df = rbind(output_df, ldf)
}
colnames(output_df) = c("Classes","Data","Len")
# Stacked barplot with multiple groups
ggplot(data=output_df, aes(x=Classes, y=Len, fill=Data)) +
 theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_bar(stat="identity")
```


```{r}
statistics = function(x){
  q50 = median(x,na.rm=TRUE)
  left_limit = min(x,na.rm=TRUE)
  rigth_limit = max(x,na.rm=TRUE)
  res = c(q50, left_limit, rigth_limit)
  return(res)
  }

trajectories =  function(data_st){
  trajectories_df = NULL
  for(k in unique(data_st$CLASS_NAME)){
    index = which(data_st$CLASS_NAME == k)
    trajectories = apply(data_st[index,c(-1,-2)], 2, statistics)
    trajectories_confidence = data.frame(k,day_shoot,t(trajectories))
    colnames(trajectories_confidence) = c('id','day','median','lower_limit','upper_limit')
    trajectories_df = rbind(trajectories_df,trajectories_confidence)
  }
  return(trajectories_df)
}
```

##Agricultural areas

```{r}
query_dataset2 = dataset2[dataset2$CLASS_NAME %in% c('Rice_fields',
                                                   'Herbaceous_periodic',
                                                   'Vineyard', 'Orchards', 'Olive_trees',
                                                   'Herbaceous_permanet') 
                                                   ,]

trajectories_agricultur= trajectories(query_dataset2)

ggplot(trajectories_agricultur, aes(x=day, y=median, color = id)) +
  geom_line(aes(x=day, y = median, color=id)) +
  geom_ribbon(aes(ymin=lower_limit,ymax=upper_limit,fill=id),color="grey70",alpha=0.4)+
  facet_grid(id~.)+ theme(legend.position="none")
```

Large part of the variability is visible between October and November of the year. Therefore, we expect the classifiers work better for this specific periods in which the trajectories depict differences in their tendency and their dispersions. Besides that, it is important to highlight tree more aspects. 

Firstly, rice fields trajectories are the only ones in all the dataset that represent strong differences respect the other trajectories. In this sense, we expect that this imply good accuracy in its classification viewed from time series analysis, however, it looks a bad scenary for the rest of the classes in which trend is almost the same and their variance continue being high. Therefore, this will imply for the next attempt to account with a different index vegetation that can highly more difference between the classes that have vegetation.

Secondly, for herbaceus periodic trajectories, we account with a strong dispersion over the year and it is difficult to trace a specific trend for this class. The reason by which we have this behavior may be given for the mixture of more classes inside this class. That is, inside this class we have two classes, one vegetation that is irrigated and another one no irrigated. This scenario leads to another problem in the application of time series analysis, that is, the application based on pure signals.

Finally, the third aspect is related with the trajectory of the land cover type called Orchards. Orchards belong to sparsaly vegetated areas whose spectral signatures can be similar to classes such as non - vegetated or herbaceus permanent, so that we will probably have problems in its classification.

##Forest and seminatural areas

```{r}
query_dataset3 = dataset2[dataset2$CLASS_NAME %in% c('Holm_and_Cork_Trees',
                                                   'Eucalyptus_trees',
                                                   'Coniferous_trees',
                                                   'Natural_Herbaceous') 
                                                   ,]

trajectories_forest_sem= trajectories(query_dataset3)

ggplot(trajectories_forest_sem, aes(x=day, y = median, color = id)) +
  geom_line(aes(x=day, y=median, color=id)) +
  geom_ribbon(aes(ymin=lower_limit,ymax=upper_limit,fill=id),color="grey70",alpha=0.4)+
  facet_grid(id~.)+ theme(legend.position="none")
```
